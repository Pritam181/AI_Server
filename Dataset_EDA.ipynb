{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and describing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Flow_ID</th>\n",
       "      <th>Src_IP</th>\n",
       "      <th>Src_Port</th>\n",
       "      <th>Dst_IP</th>\n",
       "      <th>Dst_Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Flow_Duration</th>\n",
       "      <th>Tot_Fwd_Pkts</th>\n",
       "      <th>Tot_Bwd_Pkts</th>\n",
       "      <th>...</th>\n",
       "      <th>Active_Std</th>\n",
       "      <th>Active_Max</th>\n",
       "      <th>Active_Min</th>\n",
       "      <th>Idle_Mean</th>\n",
       "      <th>Idle_Std</th>\n",
       "      <th>Idle_Max</th>\n",
       "      <th>Idle_Min</th>\n",
       "      <th>Label</th>\n",
       "      <th>Cat</th>\n",
       "      <th>Sub_Cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192.168.0.13-192.168.0.16-10000-10101-17</td>\n",
       "      <td>192.168.0.13</td>\n",
       "      <td>10000</td>\n",
       "      <td>192.168.0.16</td>\n",
       "      <td>10101</td>\n",
       "      <td>17</td>\n",
       "      <td>25/07/2019 03:25:53 AM</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Anomaly</td>\n",
       "      <td>Mirai</td>\n",
       "      <td>Mirai-Ackflooding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>192.168.0.13-222.160.179.132-554-2179-6</td>\n",
       "      <td>222.160.179.132</td>\n",
       "      <td>2179</td>\n",
       "      <td>192.168.0.13</td>\n",
       "      <td>554</td>\n",
       "      <td>6</td>\n",
       "      <td>26/05/2019 10:11:06 PM</td>\n",
       "      <td>5310</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2655.0</td>\n",
       "      <td>2261.327486</td>\n",
       "      <td>4254.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>Anomaly</td>\n",
       "      <td>DoS</td>\n",
       "      <td>DoS-Synflooding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>192.168.0.13-192.168.0.16-9020-52727-6</td>\n",
       "      <td>192.168.0.16</td>\n",
       "      <td>52727</td>\n",
       "      <td>192.168.0.13</td>\n",
       "      <td>9020</td>\n",
       "      <td>6</td>\n",
       "      <td>11/07/2019 01:24:48 AM</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.5</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>71.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Anomaly</td>\n",
       "      <td>Scan</td>\n",
       "      <td>Scan Port OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>192.168.0.13-192.168.0.16-9020-52964-6</td>\n",
       "      <td>192.168.0.16</td>\n",
       "      <td>52964</td>\n",
       "      <td>192.168.0.13</td>\n",
       "      <td>9020</td>\n",
       "      <td>6</td>\n",
       "      <td>04/09/2019 03:58:17 AM</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>151.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>Anomaly</td>\n",
       "      <td>Mirai</td>\n",
       "      <td>Mirai-Hostbruteforceg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>192.168.0.1-239.255.255.250-36763-1900-17</td>\n",
       "      <td>192.168.0.1</td>\n",
       "      <td>36763</td>\n",
       "      <td>239.255.255.250</td>\n",
       "      <td>1900</td>\n",
       "      <td>17</td>\n",
       "      <td>10/09/2019 01:41:18 AM</td>\n",
       "      <td>153</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.5</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>77.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Anomaly</td>\n",
       "      <td>Mirai</td>\n",
       "      <td>Mirai-Hostbruteforceg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625778</th>\n",
       "      <td>192.168.0.24-210.89.164.90-56112-8043-17</td>\n",
       "      <td>192.168.0.24</td>\n",
       "      <td>56112</td>\n",
       "      <td>210.89.164.90</td>\n",
       "      <td>8043</td>\n",
       "      <td>17</td>\n",
       "      <td>25/07/2019 03:25:00 AM</td>\n",
       "      <td>277</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>277.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>Anomaly</td>\n",
       "      <td>Mirai</td>\n",
       "      <td>Mirai-UDP Flooding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625779</th>\n",
       "      <td>192.168.0.13-222.131.171.244-554-4570-6</td>\n",
       "      <td>222.131.171.244</td>\n",
       "      <td>4570</td>\n",
       "      <td>192.168.0.13</td>\n",
       "      <td>554</td>\n",
       "      <td>6</td>\n",
       "      <td>26/05/2019 10:06:51 PM</td>\n",
       "      <td>1658</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1658.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1658.0</td>\n",
       "      <td>1658.0</td>\n",
       "      <td>Anomaly</td>\n",
       "      <td>DoS</td>\n",
       "      <td>DoS-Synflooding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625780</th>\n",
       "      <td>192.168.0.13-192.168.0.16-9020-52739-6</td>\n",
       "      <td>192.168.0.16</td>\n",
       "      <td>52739</td>\n",
       "      <td>192.168.0.13</td>\n",
       "      <td>9020</td>\n",
       "      <td>6</td>\n",
       "      <td>11/07/2019 01:29:09 AM</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>Anomaly</td>\n",
       "      <td>Scan</td>\n",
       "      <td>Scan Port OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625781</th>\n",
       "      <td>192.168.0.13-192.168.0.16-9020-49784-6</td>\n",
       "      <td>192.168.0.13</td>\n",
       "      <td>9020</td>\n",
       "      <td>192.168.0.16</td>\n",
       "      <td>49784</td>\n",
       "      <td>6</td>\n",
       "      <td>20/05/2019 05:00:29 AM</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>7.071068</td>\n",
       "      <td>125.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625782</th>\n",
       "      <td>192.168.0.13-192.168.0.16-10000-10101-17</td>\n",
       "      <td>192.168.0.13</td>\n",
       "      <td>10000</td>\n",
       "      <td>192.168.0.16</td>\n",
       "      <td>10101</td>\n",
       "      <td>17</td>\n",
       "      <td>25/07/2019 03:25:10 AM</td>\n",
       "      <td>198</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>32.526912</td>\n",
       "      <td>122.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Anomaly</td>\n",
       "      <td>Mirai</td>\n",
       "      <td>Mirai-UDP Flooding</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>625783 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Flow_ID           Src_IP  Src_Port  \\\n",
       "0        192.168.0.13-192.168.0.16-10000-10101-17     192.168.0.13     10000   \n",
       "1         192.168.0.13-222.160.179.132-554-2179-6  222.160.179.132      2179   \n",
       "2          192.168.0.13-192.168.0.16-9020-52727-6     192.168.0.16     52727   \n",
       "3          192.168.0.13-192.168.0.16-9020-52964-6     192.168.0.16     52964   \n",
       "4       192.168.0.1-239.255.255.250-36763-1900-17      192.168.0.1     36763   \n",
       "...                                           ...              ...       ...   \n",
       "625778   192.168.0.24-210.89.164.90-56112-8043-17     192.168.0.24     56112   \n",
       "625779    192.168.0.13-222.131.171.244-554-4570-6  222.131.171.244      4570   \n",
       "625780     192.168.0.13-192.168.0.16-9020-52739-6     192.168.0.16     52739   \n",
       "625781     192.168.0.13-192.168.0.16-9020-49784-6     192.168.0.13      9020   \n",
       "625782   192.168.0.13-192.168.0.16-10000-10101-17     192.168.0.13     10000   \n",
       "\n",
       "                 Dst_IP  Dst_Port  Protocol               Timestamp  \\\n",
       "0          192.168.0.16     10101        17  25/07/2019 03:25:53 AM   \n",
       "1          192.168.0.13       554         6  26/05/2019 10:11:06 PM   \n",
       "2          192.168.0.13      9020         6  11/07/2019 01:24:48 AM   \n",
       "3          192.168.0.13      9020         6  04/09/2019 03:58:17 AM   \n",
       "4       239.255.255.250      1900        17  10/09/2019 01:41:18 AM   \n",
       "...                 ...       ...       ...                     ...   \n",
       "625778    210.89.164.90      8043        17  25/07/2019 03:25:00 AM   \n",
       "625779     192.168.0.13       554         6  26/05/2019 10:06:51 PM   \n",
       "625780     192.168.0.13      9020         6  11/07/2019 01:29:09 AM   \n",
       "625781     192.168.0.16     49784         6  20/05/2019 05:00:29 AM   \n",
       "625782     192.168.0.16     10101        17  25/07/2019 03:25:10 AM   \n",
       "\n",
       "        Flow_Duration  Tot_Fwd_Pkts  Tot_Bwd_Pkts  ...  Active_Std  \\\n",
       "0                  75             1             1  ...         0.0   \n",
       "1                5310             1             2  ...         0.0   \n",
       "2                 141             0             3  ...         0.0   \n",
       "3                 151             0             2  ...         0.0   \n",
       "4                 153             2             1  ...         0.0   \n",
       "...               ...           ...           ...  ...         ...   \n",
       "625778            277             1             1  ...         0.0   \n",
       "625779           1658             0             2  ...         0.0   \n",
       "625780             77             1             1  ...         0.0   \n",
       "625781            240             2             1  ...         0.0   \n",
       "625782            198             2             1  ...         0.0   \n",
       "\n",
       "        Active_Max  Active_Min  Idle_Mean     Idle_Std  Idle_Max  Idle_Min  \\\n",
       "0              0.0         0.0       75.0     0.000000      75.0      75.0   \n",
       "1              0.0         0.0     2655.0  2261.327486    4254.0    1056.0   \n",
       "2              0.0         0.0       70.5     0.707107      71.0      70.0   \n",
       "3              0.0         0.0      151.0     0.000000     151.0     151.0   \n",
       "4              0.0         0.0       76.5     0.707107      77.0      76.0   \n",
       "...            ...         ...        ...          ...       ...       ...   \n",
       "625778         0.0         0.0      277.0     0.000000     277.0     277.0   \n",
       "625779         0.0         0.0     1658.0     0.000000    1658.0    1658.0   \n",
       "625780         0.0         0.0       77.0     0.000000      77.0      77.0   \n",
       "625781         0.0         0.0      120.0     7.071068     125.0     115.0   \n",
       "625782         0.0         0.0       99.0    32.526912     122.0      76.0   \n",
       "\n",
       "          Label     Cat                Sub_Cat  \n",
       "0       Anomaly   Mirai      Mirai-Ackflooding  \n",
       "1       Anomaly     DoS        DoS-Synflooding  \n",
       "2       Anomaly    Scan           Scan Port OS  \n",
       "3       Anomaly   Mirai  Mirai-Hostbruteforceg  \n",
       "4       Anomaly   Mirai  Mirai-Hostbruteforceg  \n",
       "...         ...     ...                    ...  \n",
       "625778  Anomaly   Mirai     Mirai-UDP Flooding  \n",
       "625779  Anomaly     DoS        DoS-Synflooding  \n",
       "625780  Anomaly    Scan           Scan Port OS  \n",
       "625781   Normal  Normal                 Normal  \n",
       "625782  Anomaly   Mirai     Mirai-UDP Flooding  \n",
       "\n",
       "[625783 rows x 86 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(\"IoT Network Intrusion Dataset.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Flow_ID', 'Src_IP', 'Src_Port', 'Dst_IP', 'Dst_Port', 'Protocol',\n",
       "       'Timestamp', 'Flow_Duration', 'Tot_Fwd_Pkts', 'Tot_Bwd_Pkts',\n",
       "       'TotLen_Fwd_Pkts', 'TotLen_Bwd_Pkts', 'Fwd_Pkt_Len_Max',\n",
       "       'Fwd_Pkt_Len_Min', 'Fwd_Pkt_Len_Mean', 'Fwd_Pkt_Len_Std',\n",
       "       'Bwd_Pkt_Len_Max', 'Bwd_Pkt_Len_Min', 'Bwd_Pkt_Len_Mean',\n",
       "       'Bwd_Pkt_Len_Std', 'Flow_Byts/s', 'Flow_Pkts/s', 'Flow_IAT_Mean',\n",
       "       'Flow_IAT_Std', 'Flow_IAT_Max', 'Flow_IAT_Min', 'Fwd_IAT_Tot',\n",
       "       'Fwd_IAT_Mean', 'Fwd_IAT_Std', 'Fwd_IAT_Max', 'Fwd_IAT_Min',\n",
       "       'Bwd_IAT_Tot', 'Bwd_IAT_Mean', 'Bwd_IAT_Std', 'Bwd_IAT_Max',\n",
       "       'Bwd_IAT_Min', 'Fwd_PSH_Flags', 'Bwd_PSH_Flags', 'Fwd_URG_Flags',\n",
       "       'Bwd_URG_Flags', 'Fwd_Header_Len', 'Bwd_Header_Len', 'Fwd_Pkts/s',\n",
       "       'Bwd_Pkts/s', 'Pkt_Len_Min', 'Pkt_Len_Max', 'Pkt_Len_Mean',\n",
       "       'Pkt_Len_Std', 'Pkt_Len_Var', 'FIN_Flag_Cnt', 'SYN_Flag_Cnt',\n",
       "       'RST_Flag_Cnt', 'PSH_Flag_Cnt', 'ACK_Flag_Cnt', 'URG_Flag_Cnt',\n",
       "       'CWE_Flag_Count', 'ECE_Flag_Cnt', 'Down/Up_Ratio', 'Pkt_Size_Avg',\n",
       "       'Fwd_Seg_Size_Avg', 'Bwd_Seg_Size_Avg', 'Fwd_Byts/b_Avg',\n",
       "       'Fwd_Pkts/b_Avg', 'Fwd_Blk_Rate_Avg', 'Bwd_Byts/b_Avg',\n",
       "       'Bwd_Pkts/b_Avg', 'Bwd_Blk_Rate_Avg', 'Subflow_Fwd_Pkts',\n",
       "       'Subflow_Fwd_Byts', 'Subflow_Bwd_Pkts', 'Subflow_Bwd_Byts',\n",
       "       'Init_Fwd_Win_Byts', 'Init_Bwd_Win_Byts', 'Fwd_Act_Data_Pkts',\n",
       "       'Fwd_Seg_Size_Min', 'Active_Mean', 'Active_Std', 'Active_Max',\n",
       "       'Active_Min', 'Idle_Mean', 'Idle_Std', 'Idle_Max', 'Idle_Min', 'Label',\n",
       "       'Cat', 'Sub_Cat'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nagad\\Amity MCA\\Sem 2\\AI-IDS-detection\\iotvenv\\Lib\\site-packages\\pandas\\core\\nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n",
      "c:\\Users\\nagad\\Amity MCA\\Sem 2\\AI-IDS-detection\\iotvenv\\Lib\\site-packages\\pandas\\core\\nanops.py:1016: RuntimeWarning: invalid value encountered in subtract\n",
      "  sqr = _ensure_numeric((avg - values) ** 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Src_Port</th>\n",
       "      <th>Dst_Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Flow_Duration</th>\n",
       "      <th>Tot_Fwd_Pkts</th>\n",
       "      <th>Tot_Bwd_Pkts</th>\n",
       "      <th>TotLen_Fwd_Pkts</th>\n",
       "      <th>TotLen_Bwd_Pkts</th>\n",
       "      <th>Fwd_Pkt_Len_Max</th>\n",
       "      <th>Fwd_Pkt_Len_Min</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd_Act_Data_Pkts</th>\n",
       "      <th>Fwd_Seg_Size_Min</th>\n",
       "      <th>Active_Mean</th>\n",
       "      <th>Active_Std</th>\n",
       "      <th>Active_Max</th>\n",
       "      <th>Active_Min</th>\n",
       "      <th>Idle_Mean</th>\n",
       "      <th>Idle_Std</th>\n",
       "      <th>Idle_Max</th>\n",
       "      <th>Idle_Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>625783.000000</td>\n",
       "      <td>625783.000000</td>\n",
       "      <td>625783.000000</td>\n",
       "      <td>625783.000000</td>\n",
       "      <td>625783.000000</td>\n",
       "      <td>625783.00000</td>\n",
       "      <td>625783.000000</td>\n",
       "      <td>625783.000000</td>\n",
       "      <td>625783.000000</td>\n",
       "      <td>625783.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>625783.000000</td>\n",
       "      <td>625783.0</td>\n",
       "      <td>625783.000000</td>\n",
       "      <td>625783.000000</td>\n",
       "      <td>625783.000000</td>\n",
       "      <td>625783.000000</td>\n",
       "      <td>625783.000000</td>\n",
       "      <td>625783.000000</td>\n",
       "      <td>625783.000000</td>\n",
       "      <td>625783.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>35026.156190</td>\n",
       "      <td>16387.027479</td>\n",
       "      <td>9.971436</td>\n",
       "      <td>635.422865</td>\n",
       "      <td>1.675566</td>\n",
       "      <td>1.46853</td>\n",
       "      <td>570.738980</td>\n",
       "      <td>929.280973</td>\n",
       "      <td>392.489726</td>\n",
       "      <td>348.126571</td>\n",
       "      <td>...</td>\n",
       "      <td>1.509913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.764405</td>\n",
       "      <td>0.353385</td>\n",
       "      <td>4.248735</td>\n",
       "      <td>3.462159</td>\n",
       "      <td>502.503832</td>\n",
       "      <td>52.403995</td>\n",
       "      <td>561.540512</td>\n",
       "      <td>467.264459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>24721.047752</td>\n",
       "      <td>17550.363037</td>\n",
       "      <td>5.379857</td>\n",
       "      <td>3496.740723</td>\n",
       "      <td>4.309970</td>\n",
       "      <td>1.21949</td>\n",
       "      <td>1161.873195</td>\n",
       "      <td>1731.760875</td>\n",
       "      <td>619.575865</td>\n",
       "      <td>588.161845</td>\n",
       "      <td>...</td>\n",
       "      <td>4.332737</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.064508</td>\n",
       "      <td>20.723370</td>\n",
       "      <td>88.934148</td>\n",
       "      <td>64.111043</td>\n",
       "      <td>2112.957360</td>\n",
       "      <td>1153.184897</td>\n",
       "      <td>2866.497606</td>\n",
       "      <td>1931.909971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9020.000000</td>\n",
       "      <td>8899.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>71.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>51991.000000</td>\n",
       "      <td>9020.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>93.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>78.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>56361.000000</td>\n",
       "      <td>10101.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>221.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>1388.000000</td>\n",
       "      <td>1441.000000</td>\n",
       "      <td>1388.000000</td>\n",
       "      <td>386.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>1.527525</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>130.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>65500.000000</td>\n",
       "      <td>65371.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>99984.000000</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>560.00000</td>\n",
       "      <td>109846.000000</td>\n",
       "      <td>773284.000000</td>\n",
       "      <td>1464.000000</td>\n",
       "      <td>1464.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9044.625000</td>\n",
       "      <td>8598.658250</td>\n",
       "      <td>26785.000000</td>\n",
       "      <td>6659.000000</td>\n",
       "      <td>99973.000000</td>\n",
       "      <td>67071.906623</td>\n",
       "      <td>99973.000000</td>\n",
       "      <td>99973.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Src_Port       Dst_Port       Protocol  Flow_Duration  \\\n",
       "count  625783.000000  625783.000000  625783.000000  625783.000000   \n",
       "mean    35026.156190   16387.027479       9.971436     635.422865   \n",
       "std     24721.047752   17550.363037       5.379857    3496.740723   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%      9020.000000    8899.000000       6.000000      76.000000   \n",
       "50%     51991.000000    9020.000000       6.000000     132.000000   \n",
       "75%     56361.000000   10101.000000      17.000000     221.000000   \n",
       "max     65500.000000   65371.000000      17.000000   99984.000000   \n",
       "\n",
       "        Tot_Fwd_Pkts  Tot_Bwd_Pkts  TotLen_Fwd_Pkts  TotLen_Bwd_Pkts  \\\n",
       "count  625783.000000  625783.00000    625783.000000    625783.000000   \n",
       "mean        1.675566       1.46853       570.738980       929.280973   \n",
       "std         4.309970       1.21949      1161.873195      1731.760875   \n",
       "min         0.000000       1.00000         0.000000         0.000000   \n",
       "25%         0.000000       1.00000         0.000000        18.000000   \n",
       "50%         1.000000       1.00000        32.000000       104.000000   \n",
       "75%         2.000000       2.00000      1388.000000      1441.000000   \n",
       "max       186.000000     560.00000    109846.000000    773284.000000   \n",
       "\n",
       "       Fwd_Pkt_Len_Max  Fwd_Pkt_Len_Min  ...  Fwd_Act_Data_Pkts  \\\n",
       "count    625783.000000    625783.000000  ...      625783.000000   \n",
       "mean        392.489726       348.126571  ...           1.509913   \n",
       "std         619.575865       588.161845  ...           4.332737   \n",
       "min           0.000000         0.000000  ...           0.000000   \n",
       "25%           0.000000         0.000000  ...           0.000000   \n",
       "50%          30.000000        30.000000  ...           1.000000   \n",
       "75%        1388.000000       386.000000  ...           1.000000   \n",
       "max        1464.000000      1464.000000  ...         186.000000   \n",
       "\n",
       "       Fwd_Seg_Size_Min    Active_Mean     Active_Std     Active_Max  \\\n",
       "count          625783.0  625783.000000  625783.000000  625783.000000   \n",
       "mean                0.0       3.764405       0.353385       4.248735   \n",
       "std                 0.0      68.064508      20.723370      88.934148   \n",
       "min                 0.0       0.000000       0.000000       0.000000   \n",
       "25%                 0.0       0.000000       0.000000       0.000000   \n",
       "50%                 0.0       0.000000       0.000000       0.000000   \n",
       "75%                 0.0       0.000000       0.000000       0.000000   \n",
       "max                 0.0    9044.625000    8598.658250   26785.000000   \n",
       "\n",
       "          Active_Min      Idle_Mean       Idle_Std       Idle_Max  \\\n",
       "count  625783.000000  625783.000000  625783.000000  625783.000000   \n",
       "mean        3.462159     502.503832      52.403995     561.540512   \n",
       "std        64.111043    2112.957360    1153.184897    2866.497606   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000      73.000000       0.000000      74.000000   \n",
       "50%         0.000000      93.500000       0.000000     114.000000   \n",
       "75%         0.000000     141.000000       1.527525     154.000000   \n",
       "max      6659.000000   99973.000000   67071.906623   99973.000000   \n",
       "\n",
       "            Idle_Min  \n",
       "count  625783.000000  \n",
       "mean      467.264459  \n",
       "std      1931.909971  \n",
       "min         0.000000  \n",
       "25%        71.000000  \n",
       "50%        78.000000  \n",
       "75%       130.000000  \n",
       "max     99973.000000  \n",
       "\n",
       "[8 rows x 79 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Src_Port</th>\n",
       "      <th>Dst_Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Flow_Duration</th>\n",
       "      <th>Tot_Fwd_Pkts</th>\n",
       "      <th>Tot_Bwd_Pkts</th>\n",
       "      <th>TotLen_Fwd_Pkts</th>\n",
       "      <th>TotLen_Bwd_Pkts</th>\n",
       "      <th>Fwd_Pkt_Len_Max</th>\n",
       "      <th>Fwd_Pkt_Len_Min</th>\n",
       "      <th>...</th>\n",
       "      <th>Fwd_Seg_Size_Min</th>\n",
       "      <th>Active_Mean</th>\n",
       "      <th>Active_Std</th>\n",
       "      <th>Active_Max</th>\n",
       "      <th>Active_Min</th>\n",
       "      <th>Idle_Mean</th>\n",
       "      <th>Idle_Std</th>\n",
       "      <th>Idle_Max</th>\n",
       "      <th>Idle_Min</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>10101</td>\n",
       "      <td>17</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>982.0</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>982.0</td>\n",
       "      <td>982.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>Anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2179</td>\n",
       "      <td>554</td>\n",
       "      <td>6</td>\n",
       "      <td>5310</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2655.0</td>\n",
       "      <td>2261.327486</td>\n",
       "      <td>4254.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>Anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52727</td>\n",
       "      <td>9020</td>\n",
       "      <td>6</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2806.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.5</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>71.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52964</td>\n",
       "      <td>9020</td>\n",
       "      <td>6</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2776.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>151.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>Anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36763</td>\n",
       "      <td>1900</td>\n",
       "      <td>17</td>\n",
       "      <td>153</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>886.0</td>\n",
       "      <td>420.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.5</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>77.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625778</th>\n",
       "      <td>56112</td>\n",
       "      <td>8043</td>\n",
       "      <td>17</td>\n",
       "      <td>277</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>277.0</td>\n",
       "      <td>277.0</td>\n",
       "      <td>Anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625779</th>\n",
       "      <td>4570</td>\n",
       "      <td>554</td>\n",
       "      <td>6</td>\n",
       "      <td>1658</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1658.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1658.0</td>\n",
       "      <td>1658.0</td>\n",
       "      <td>Anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625780</th>\n",
       "      <td>52739</td>\n",
       "      <td>9020</td>\n",
       "      <td>6</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>77.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>Anomaly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625781</th>\n",
       "      <td>9020</td>\n",
       "      <td>49784</td>\n",
       "      <td>6</td>\n",
       "      <td>240</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2776.0</td>\n",
       "      <td>1388.0</td>\n",
       "      <td>1388.0</td>\n",
       "      <td>1388.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>7.071068</td>\n",
       "      <td>125.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625782</th>\n",
       "      <td>10000</td>\n",
       "      <td>10101</td>\n",
       "      <td>17</td>\n",
       "      <td>198</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2860.0</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>1430.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>32.526912</td>\n",
       "      <td>122.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Anomaly</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>625783 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Src_Port  Dst_Port  Protocol  Flow_Duration  Tot_Fwd_Pkts  \\\n",
       "0          10000     10101        17             75             1   \n",
       "1           2179       554         6           5310             1   \n",
       "2          52727      9020         6            141             0   \n",
       "3          52964      9020         6            151             0   \n",
       "4          36763      1900        17            153             2   \n",
       "...          ...       ...       ...            ...           ...   \n",
       "625778     56112      8043        17            277             1   \n",
       "625779      4570       554         6           1658             0   \n",
       "625780     52739      9020         6             77             1   \n",
       "625781      9020     49784         6            240             2   \n",
       "625782     10000     10101        17            198             2   \n",
       "\n",
       "        Tot_Bwd_Pkts  TotLen_Fwd_Pkts  TotLen_Bwd_Pkts  Fwd_Pkt_Len_Max  \\\n",
       "0                  1            982.0           1430.0            982.0   \n",
       "1                  2              0.0              0.0              0.0   \n",
       "2                  3              0.0           2806.0              0.0   \n",
       "3                  2              0.0           2776.0              0.0   \n",
       "4                  1            886.0            420.0            452.0   \n",
       "...              ...              ...              ...              ...   \n",
       "625778             1             18.0             18.0             18.0   \n",
       "625779             2              0.0              0.0              0.0   \n",
       "625780             1              0.0              0.0              0.0   \n",
       "625781             1           2776.0           1388.0           1388.0   \n",
       "625782             1           2860.0           1430.0           1430.0   \n",
       "\n",
       "        Fwd_Pkt_Len_Min  ...  Fwd_Seg_Size_Min  Active_Mean  Active_Std  \\\n",
       "0                 982.0  ...                 0          0.0         0.0   \n",
       "1                   0.0  ...                 0          0.0         0.0   \n",
       "2                   0.0  ...                 0          0.0         0.0   \n",
       "3                   0.0  ...                 0          0.0         0.0   \n",
       "4                 434.0  ...                 0          0.0         0.0   \n",
       "...                 ...  ...               ...          ...         ...   \n",
       "625778             18.0  ...                 0          0.0         0.0   \n",
       "625779              0.0  ...                 0          0.0         0.0   \n",
       "625780              0.0  ...                 0          0.0         0.0   \n",
       "625781           1388.0  ...                 0          0.0         0.0   \n",
       "625782           1430.0  ...                 0          0.0         0.0   \n",
       "\n",
       "        Active_Max  Active_Min  Idle_Mean     Idle_Std  Idle_Max  Idle_Min  \\\n",
       "0              0.0         0.0       75.0     0.000000      75.0      75.0   \n",
       "1              0.0         0.0     2655.0  2261.327486    4254.0    1056.0   \n",
       "2              0.0         0.0       70.5     0.707107      71.0      70.0   \n",
       "3              0.0         0.0      151.0     0.000000     151.0     151.0   \n",
       "4              0.0         0.0       76.5     0.707107      77.0      76.0   \n",
       "...            ...         ...        ...          ...       ...       ...   \n",
       "625778         0.0         0.0      277.0     0.000000     277.0     277.0   \n",
       "625779         0.0         0.0     1658.0     0.000000    1658.0    1658.0   \n",
       "625780         0.0         0.0       77.0     0.000000      77.0      77.0   \n",
       "625781         0.0         0.0      120.0     7.071068     125.0     115.0   \n",
       "625782         0.0         0.0       99.0    32.526912     122.0      76.0   \n",
       "\n",
       "          Label  \n",
       "0       Anomaly  \n",
       "1       Anomaly  \n",
       "2       Anomaly  \n",
       "3       Anomaly  \n",
       "4       Anomaly  \n",
       "...         ...  \n",
       "625778  Anomaly  \n",
       "625779  Anomaly  \n",
       "625780  Anomaly  \n",
       "625781   Normal  \n",
       "625782  Anomaly  \n",
       "\n",
       "[625783 rows x 80 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= df.drop(['Src_IP', 'Flow_ID', 'Sub_Cat', 'Dst_IP', 'Timestamp', 'Cat'], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding 'Label'-> Anomaly: 1 and Normal: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df['Label'] = np.where(df['Label'] == 'Normal', 0, 1)\n",
    "#df['Cat'] = np.where(df['Cat'] == 'Normal', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "1    585710\n",
      "0     40073\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection using Genetic Algorithm (GA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 625783 entries, 0 to 625782\n",
      "Data columns (total 80 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   Src_Port           625783 non-null  int64  \n",
      " 1   Dst_Port           625783 non-null  int64  \n",
      " 2   Protocol           625783 non-null  int64  \n",
      " 3   Flow_Duration      625783 non-null  int64  \n",
      " 4   Tot_Fwd_Pkts       625783 non-null  int64  \n",
      " 5   Tot_Bwd_Pkts       625783 non-null  int64  \n",
      " 6   TotLen_Fwd_Pkts    625783 non-null  float64\n",
      " 7   TotLen_Bwd_Pkts    625783 non-null  float64\n",
      " 8   Fwd_Pkt_Len_Max    625783 non-null  float64\n",
      " 9   Fwd_Pkt_Len_Min    625783 non-null  float64\n",
      " 10  Fwd_Pkt_Len_Mean   625783 non-null  float64\n",
      " 11  Fwd_Pkt_Len_Std    625783 non-null  float64\n",
      " 12  Bwd_Pkt_Len_Max    625783 non-null  float64\n",
      " 13  Bwd_Pkt_Len_Min    625783 non-null  float64\n",
      " 14  Bwd_Pkt_Len_Mean   625783 non-null  float64\n",
      " 15  Bwd_Pkt_Len_Std    625783 non-null  float64\n",
      " 16  Flow_Byts/s        625783 non-null  float64\n",
      " 17  Flow_Pkts/s        625783 non-null  float64\n",
      " 18  Flow_IAT_Mean      625783 non-null  float64\n",
      " 19  Flow_IAT_Std       625783 non-null  float64\n",
      " 20  Flow_IAT_Max       625783 non-null  float64\n",
      " 21  Flow_IAT_Min       625783 non-null  float64\n",
      " 22  Fwd_IAT_Tot        625783 non-null  float64\n",
      " 23  Fwd_IAT_Mean       625783 non-null  float64\n",
      " 24  Fwd_IAT_Std        625783 non-null  float64\n",
      " 25  Fwd_IAT_Max        625783 non-null  float64\n",
      " 26  Fwd_IAT_Min        625783 non-null  float64\n",
      " 27  Bwd_IAT_Tot        625783 non-null  float64\n",
      " 28  Bwd_IAT_Mean       625783 non-null  float64\n",
      " 29  Bwd_IAT_Std        625783 non-null  float64\n",
      " 30  Bwd_IAT_Max        625783 non-null  float64\n",
      " 31  Bwd_IAT_Min        625783 non-null  float64\n",
      " 32  Fwd_PSH_Flags      625783 non-null  int64  \n",
      " 33  Bwd_PSH_Flags      625783 non-null  int64  \n",
      " 34  Fwd_URG_Flags      625783 non-null  int64  \n",
      " 35  Bwd_URG_Flags      625783 non-null  int64  \n",
      " 36  Fwd_Header_Len     625783 non-null  int64  \n",
      " 37  Bwd_Header_Len     625783 non-null  int64  \n",
      " 38  Fwd_Pkts/s         625783 non-null  float64\n",
      " 39  Bwd_Pkts/s         625783 non-null  float64\n",
      " 40  Pkt_Len_Min        625783 non-null  float64\n",
      " 41  Pkt_Len_Max        625783 non-null  float64\n",
      " 42  Pkt_Len_Mean       625783 non-null  float64\n",
      " 43  Pkt_Len_Std        625783 non-null  float64\n",
      " 44  Pkt_Len_Var        625783 non-null  float64\n",
      " 45  FIN_Flag_Cnt       625783 non-null  int64  \n",
      " 46  SYN_Flag_Cnt       625783 non-null  int64  \n",
      " 47  RST_Flag_Cnt       625783 non-null  int64  \n",
      " 48  PSH_Flag_Cnt       625783 non-null  int64  \n",
      " 49  ACK_Flag_Cnt       625783 non-null  int64  \n",
      " 50  URG_Flag_Cnt       625783 non-null  int64  \n",
      " 51  CWE_Flag_Count     625783 non-null  int64  \n",
      " 52  ECE_Flag_Cnt       625783 non-null  int64  \n",
      " 53  Down/Up_Ratio      625783 non-null  float64\n",
      " 54  Pkt_Size_Avg       625783 non-null  float64\n",
      " 55  Fwd_Seg_Size_Avg   625783 non-null  float64\n",
      " 56  Bwd_Seg_Size_Avg   625783 non-null  float64\n",
      " 57  Fwd_Byts/b_Avg     625783 non-null  int64  \n",
      " 58  Fwd_Pkts/b_Avg     625783 non-null  int64  \n",
      " 59  Fwd_Blk_Rate_Avg   625783 non-null  int64  \n",
      " 60  Bwd_Byts/b_Avg     625783 non-null  int64  \n",
      " 61  Bwd_Pkts/b_Avg     625783 non-null  int64  \n",
      " 62  Bwd_Blk_Rate_Avg   625783 non-null  int64  \n",
      " 63  Subflow_Fwd_Pkts   625783 non-null  int64  \n",
      " 64  Subflow_Fwd_Byts   625783 non-null  int64  \n",
      " 65  Subflow_Bwd_Pkts   625783 non-null  int64  \n",
      " 66  Subflow_Bwd_Byts   625783 non-null  int64  \n",
      " 67  Init_Fwd_Win_Byts  625783 non-null  int64  \n",
      " 68  Init_Bwd_Win_Byts  625783 non-null  int64  \n",
      " 69  Fwd_Act_Data_Pkts  625783 non-null  int64  \n",
      " 70  Fwd_Seg_Size_Min   625783 non-null  int64  \n",
      " 71  Active_Mean        625783 non-null  float64\n",
      " 72  Active_Std         625783 non-null  float64\n",
      " 73  Active_Max         625783 non-null  float64\n",
      " 74  Active_Min         625783 non-null  float64\n",
      " 75  Idle_Mean          625783 non-null  float64\n",
      " 76  Idle_Std           625783 non-null  float64\n",
      " 77  Idle_Max           625783 non-null  float64\n",
      " 78  Idle_Min           625783 non-null  float64\n",
      " 79  Label              625783 non-null  int64  \n",
      "dtypes: float64(45), int64(35)\n",
      "memory usage: 381.9 MB\n"
     ]
    }
   ],
   "source": [
    "df= df.select_dtypes(exclude=['object'])\n",
    "#df = df.loc[:, (df.dtypes != 'object') | (df.columns == 'Label')]\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handle missing and infinite values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.replace([np.inf, -np.inf], np.nan, inplace=True)  # Replace infinite values\n",
    "#df.fillna(df.mean(), inplace=True)  # Fill NaNs with column mean\n",
    "\n",
    "# Replace infinite values in numeric columns\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Fill NaNs with column mean (only for numeric columns)\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns  # Identify numeric columns\n",
    "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "#df[df.columns] = scaler.fit_transform(df[df.columns])\n",
    "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 625783 samples, 79 features\n",
      "Starting Genetic Algorithm for feature selection...\n",
      "Generation 0: Max Fitness = 0.9470, Avg = 0.9410\n",
      "Generation 1: Max Fitness = 0.9475, Avg = 0.9451\n",
      "Generation 2: Max Fitness = 0.9475, Avg = 0.9461\n",
      "Generation 3: Max Fitness = 0.9475, Avg = 0.9467\n",
      "Early stopping at generation 3 - minimal improvement\n",
      "GA completed in 0.73 seconds\n",
      "Selected 39 features out of 79\n",
      "\n",
      "Selected features: [1, 2, 6, 7, 8, 9, 10, 13, 14, 16, 17, 18, 19, 22, 24, 26, 30, 32, 33, 35, 36, 38, 40, 42, 43, 47, 50, 56, 59, 60, 62, 63, 64, 65, 68, 70, 75, 77, 78]\n",
      "Number of selected features: 39/79\n",
      "\n",
      "Evaluating selected feature subset...\n",
      "Training accuracy: 0.9988\n",
      "Test accuracy: 0.9977\n",
      "\n",
      "Comparing with baseline (all features):\n",
      "All features - Training accuracy: 1.0000\n",
      "All features - Test accuracy: 0.9988\n",
      "\n",
      "Top 10 important features in selected subset:\n",
      "              Feature  Importance\n",
      "0            Dst_Port    0.295672\n",
      "34  Init_Bwd_Win_Byts    0.116284\n",
      "37           Idle_Max    0.079068\n",
      "10        Flow_Pkts/s    0.073463\n",
      "12       Flow_IAT_Std    0.037090\n",
      "11      Flow_IAT_Mean    0.035335\n",
      "20     Fwd_Header_Len    0.032357\n",
      "36          Idle_Mean    0.030959\n",
      "38           Idle_Min    0.029009\n",
      "13        Fwd_IAT_Tot    0.024031\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from deap import base, creator, tools, algorithms\n",
    "import random\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from multiprocessing import Pool\n",
    "from functools import lru_cache\n",
    "import time\n",
    "\n",
    "# Assume X and y are already defined from:\n",
    "X = df.drop(columns=['Label']) \n",
    "y = df['Label']\n",
    "\n",
    "# Create smaller samples for faster evaluation\n",
    "sample_size = min(2000, len(X))\n",
    "X_sample = X.sample(n=sample_size, random_state=42)\n",
    "y_sample = y.loc[X_sample.index]\n",
    "\n",
    "# Reset DEAP to avoid conflicts if running multiple times\n",
    "if 'FitnessMax' in creator.__dict__:\n",
    "    del creator.FitnessMax\n",
    "    del creator.Individual\n",
    "\n",
    "# Configure DEAP\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "n_features = X.shape[1]  # Number of features (80)\n",
    "\n",
    "# Feature selection representation: binary encoding\n",
    "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=n_features)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "# Cache for evaluation results to avoid redundant calculations\n",
    "evaluation_cache = {}\n",
    "\n",
    "def evaluate_features(individual, generation=0):\n",
    "    \"\"\"Evaluate a feature subset using classification performance\"\"\"\n",
    "    # Convert binary chromosome to feature indices\n",
    "    selected_features = tuple([i for i, val in enumerate(individual) if val == 1])\n",
    "    \n",
    "    # Return cached result if available\n",
    "    cache_key = selected_features\n",
    "    if cache_key in evaluation_cache:\n",
    "        return evaluation_cache[cache_key]\n",
    "    \n",
    "    # No features selected case\n",
    "    if len(selected_features) == 0:\n",
    "        return 0,\n",
    "    \n",
    "    # Feature subset size penalty (prefer smaller subsets)\n",
    "    subset_size = len(selected_features)\n",
    "    size_penalty = 0.001 * (subset_size / n_features)\n",
    "    \n",
    "    # Use simpler/faster evaluation for early generations\n",
    "    if generation < 5:\n",
    "        clf = LogisticRegression(max_iter=100, solver='liblinear')\n",
    "        cv_folds = 2\n",
    "    else:\n",
    "        clf = RandomForestClassifier(n_estimators=20, max_depth=10, n_jobs=-1)\n",
    "        cv_folds = 3\n",
    "    \n",
    "    try:\n",
    "        # Create feature subset\n",
    "        X_subset = X_sample.iloc[:, list(selected_features)]\n",
    "        \n",
    "        # Evaluate with cross-validation\n",
    "        scores = cross_val_score(clf, X_subset, y_sample, cv=cv_folds, scoring='accuracy')\n",
    "        fitness = np.mean(scores) - size_penalty\n",
    "        \n",
    "        # Cache the result\n",
    "        evaluation_cache[cache_key] = (fitness,)\n",
    "        return fitness,\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating features: {e}\")\n",
    "        return 0,\n",
    "\n",
    "# Register genetic operators\n",
    "toolbox.register(\"evaluate\", evaluate_features)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "# Use parallel processing if available\n",
    "# Adjust processes based on your system (comment out if causing issues)\n",
    "try:\n",
    "    pool = Pool(processes=4)\n",
    "    toolbox.register(\"map\", pool.map)\n",
    "except:\n",
    "    print(\"Parallel processing setup failed, using sequential evaluation\")\n",
    "\n",
    "def check_convergence(logbook, patience=3, threshold=0.001):\n",
    "    \"\"\"Check if GA has converged based on fitness improvement\"\"\"\n",
    "    if len(logbook) <= patience:\n",
    "        return False\n",
    "        \n",
    "    recent_best = [gen['max'] for gen in logbook[-patience:]]\n",
    "    improvement = recent_best[-1] - recent_best[0]\n",
    "    return improvement < threshold\n",
    "\n",
    "def run_ga(pop_size=20, generations=15, cx_prob=0.7, mut_prob=0.2):\n",
    "    \"\"\"Run the genetic algorithm\"\"\"\n",
    "    print(\"Starting Genetic Algorithm for feature selection...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Initialize population\n",
    "    pop = toolbox.population(n=pop_size)\n",
    "    \n",
    "    # Setup statistics tracking\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"max\", np.max)\n",
    "    \n",
    "    # GA history\n",
    "    logbook = tools.Logbook()\n",
    "    hof = tools.HallOfFame(1)\n",
    "    \n",
    "    # Evaluate initial population\n",
    "    fitnesses = list(map(toolbox.evaluate, pop))\n",
    "    for ind, fit in zip(pop, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "    \n",
    "    # Record initial stats\n",
    "    record = stats.compile(pop)\n",
    "    logbook.record(gen=0, **record)\n",
    "    print(f\"Generation 0: Max Fitness = {record['max']:.4f}, Avg = {record['avg']:.4f}\")\n",
    "    \n",
    "    # Main evolution loop\n",
    "    for gen in range(1, generations + 1):\n",
    "        # Update evaluation function with current generation\n",
    "        toolbox.register(\"evaluate\", evaluate_features, generation=gen)\n",
    "        \n",
    "        # Select and clone individuals\n",
    "        offspring = toolbox.select(pop, len(pop))\n",
    "        offspring = list(map(toolbox.clone, offspring))\n",
    "        \n",
    "        # Apply crossover and mutation\n",
    "        for i in range(1, len(offspring), 2):\n",
    "            if random.random() < cx_prob:\n",
    "                offspring[i-1], offspring[i] = toolbox.mate(offspring[i-1], offspring[i])\n",
    "                del offspring[i-1].fitness.values\n",
    "                del offspring[i].fitness.values\n",
    "        \n",
    "        for i in range(len(offspring)):\n",
    "            if random.random() < mut_prob:\n",
    "                offspring[i] = toolbox.mutate(offspring[i])[0]\n",
    "                del offspring[i].fitness.values\n",
    "        \n",
    "        # Evaluate new individuals\n",
    "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fitnesses = list(map(toolbox.evaluate, invalid_ind))\n",
    "        for ind, fit in zip(invalid_ind, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "        \n",
    "        # Replace population\n",
    "        pop[:] = offspring\n",
    "        hof.update(pop)\n",
    "        \n",
    "        # Record statistics\n",
    "        record = stats.compile(pop)\n",
    "        logbook.record(gen=gen, **record)\n",
    "        print(f\"Generation {gen}: Max Fitness = {record['max']:.4f}, Avg = {record['avg']:.4f}\")\n",
    "        \n",
    "        # Check for convergence\n",
    "        if check_convergence(logbook):\n",
    "            print(f\"Early stopping at generation {gen} - minimal improvement\")\n",
    "            break\n",
    "    \n",
    "    # Get best individual\n",
    "    best_ind = hof[0]\n",
    "    selected_features = [i for i, val in enumerate(best_ind) if val == 1]\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"GA completed in {elapsed_time:.2f} seconds\")\n",
    "    print(f\"Selected {len(selected_features)} features out of {n_features}\")\n",
    "    \n",
    "    return selected_features, best_ind.fitness.values[0], logbook\n",
    "\n",
    "def evaluate_selected_features(selected_features):\n",
    "    \"\"\"Evaluate the selected feature subset on a test set\"\"\"\n",
    "    print(\"\\nEvaluating selected feature subset...\")\n",
    "    \n",
    "    # Use the full dataset with selected features only\n",
    "    X_selected = X.iloc[:, selected_features]\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_selected, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train model\n",
    "    model = RandomForestClassifier(n_estimators=100)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    train_acc = model.score(X_train, y_train)\n",
    "    test_acc = model.score(X_test, y_test)\n",
    "    \n",
    "    print(f\"Training accuracy: {train_acc:.4f}\")\n",
    "    print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "    \n",
    "    return model, train_acc, test_acc\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    \"\"\"Main function to run the GA feature selection process\"\"\"\n",
    "    print(f\"Dataset: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "    \n",
    "    # Run GA with smaller parameters for faster execution\n",
    "    selected_features, fitness, log = run_ga(\n",
    "        pop_size=15,      # Smaller population for faster execution\n",
    "        generations=10,   # Fewer generations\n",
    "        cx_prob=0.7,      # Crossover probability\n",
    "        mut_prob=0.2      # Mutation probability\n",
    "    )\n",
    "    \n",
    "    # Display selected features\n",
    "    print(\"\\nSelected features:\", selected_features)\n",
    "    print(f\"Number of selected features: {len(selected_features)}/{n_features}\")\n",
    "    \n",
    "    # Evaluate the selected features on the full dataset\n",
    "    model, train_acc, test_acc = evaluate_selected_features(selected_features)\n",
    "    \n",
    "    # Compare with baseline (optional)\n",
    "    print(\"\\nComparing with baseline (all features):\")\n",
    "    X_train_all, X_test_all, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    model_all = RandomForestClassifier(n_estimators=100)\n",
    "    model_all.fit(X_train_all, y_train)\n",
    "    \n",
    "    all_train_acc = model_all.score(X_train_all, y_train)\n",
    "    all_test_acc = model_all.score(X_test_all, y_test)\n",
    "    \n",
    "    print(f\"All features - Training accuracy: {all_train_acc:.4f}\")\n",
    "    print(f\"All features - Test accuracy: {all_test_acc:.4f}\")\n",
    "    \n",
    "    # Feature importance of selected features\n",
    "    importances = model.feature_importances_\n",
    "    feature_names = X.columns[selected_features]\n",
    "    importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "    importance_df = importance_df.sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 10 important features in selected subset:\")\n",
    "    print(importance_df.head(10))\n",
    "    \n",
    "    return selected_features, model, importance_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        selected_features, model, importance_df = main()\n",
    "        \n",
    "        # Cleanup\n",
    "        if 'pool' in locals():\n",
    "            pool.close()\n",
    "            pool.join()\n",
    "    except Exception as e:\n",
    "        print(f\"Error in execution: {e}\")\n",
    "        if 'pool' in locals():\n",
    "            pool.close()\n",
    "            pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dst_Port</th>\n",
       "      <th>Init_Bwd_Win_Byts</th>\n",
       "      <th>Idle_Max</th>\n",
       "      <th>Flow_Pkts/s</th>\n",
       "      <th>Flow_IAT_Std</th>\n",
       "      <th>Flow_IAT_Mean</th>\n",
       "      <th>Fwd_Header_Len</th>\n",
       "      <th>Idle_Mean</th>\n",
       "      <th>Idle_Min</th>\n",
       "      <th>Fwd_IAT_Tot</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.154518</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.005329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.000750</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.222794</td>\n",
       "      <td>0.042551</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.033303</td>\n",
       "      <td>0.026557</td>\n",
       "      <td>0.005219</td>\n",
       "      <td>0.026557</td>\n",
       "      <td>0.010563</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.137982</td>\n",
       "      <td>0.028534</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.004251</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.137982</td>\n",
       "      <td>0.028534</td>\n",
       "      <td>0.001510</td>\n",
       "      <td>0.002645</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001510</td>\n",
       "      <td>0.001510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.029065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>0.003918</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.004175</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625778</th>\n",
       "      <td>0.123036</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002771</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002771</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>0.002771</td>\n",
       "      <td>0.002771</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625779</th>\n",
       "      <td>0.008475</td>\n",
       "      <td>0.222794</td>\n",
       "      <td>0.016584</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016584</td>\n",
       "      <td>0.016584</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625780</th>\n",
       "      <td>0.137982</td>\n",
       "      <td>0.498657</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>0.005191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>0.008351</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625781</th>\n",
       "      <td>0.761561</td>\n",
       "      <td>0.028534</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.002496</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.016701</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.001150</td>\n",
       "      <td>0.001254</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625782</th>\n",
       "      <td>0.154518</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>0.003026</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.004175</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.001224</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>625783 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Dst_Port  Init_Bwd_Win_Byts  Idle_Max  Flow_Pkts/s  Flow_IAT_Std  \\\n",
       "0       0.154518           0.000000  0.000750     0.005329      0.000000   \n",
       "1       0.008475           0.222794  0.042551     0.000109      0.033303   \n",
       "2       0.137982           0.028534  0.000710     0.004251      0.000010   \n",
       "3       0.137982           0.028534  0.001510     0.002645      0.000000   \n",
       "4       0.029065           0.000000  0.000770     0.003918      0.000010   \n",
       "...          ...                ...       ...          ...           ...   \n",
       "625778  0.123036           0.000000  0.002771     0.001440      0.000000   \n",
       "625779  0.008475           0.222794  0.016584     0.000237      0.000000   \n",
       "625780  0.137982           0.498657  0.000770     0.005191      0.000000   \n",
       "625781  0.761561           0.028534  0.001250     0.002496      0.000104   \n",
       "625782  0.154518           0.000000  0.001220     0.003026      0.000479   \n",
       "\n",
       "        Flow_IAT_Mean  Fwd_Header_Len  Idle_Mean  Idle_Min  Fwd_IAT_Tot  Label  \n",
       "0            0.000750        0.002088   0.000750  0.000750     0.000000    1.0  \n",
       "1            0.026557        0.005219   0.026557  0.010563     0.000000    1.0  \n",
       "2            0.000705        0.000000   0.000705  0.000700     0.000000    1.0  \n",
       "3            0.001510        0.000000   0.001510  0.001510     0.000000    1.0  \n",
       "4            0.000765        0.004175   0.000765  0.000760     0.000762    1.0  \n",
       "...               ...             ...        ...       ...          ...    ...  \n",
       "625778       0.002771        0.002088   0.002771  0.002771     0.000000    1.0  \n",
       "625779       0.016584        0.000000   0.016584  0.016584     0.000000    1.0  \n",
       "625780       0.000770        0.008351   0.000770  0.000770     0.000000    1.0  \n",
       "625781       0.001200        0.016701   0.001200  0.001150     0.001254    0.0  \n",
       "625782       0.000990        0.004175   0.000990  0.000760     0.001224    1.0  \n",
       "\n",
       "[625783 rows x 11 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_selected= df[['Dst_Port', 'Init_Bwd_Win_Byts', 'Idle_Max', 'Flow_Pkts/s', 'Flow_IAT_Std', 'Flow_IAT_Mean', 'Fwd_Header_Len', 'Idle_Mean', 'Idle_Min', 'Fwd_IAT_Tot', 'Label']]\n",
    "df_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree for Anomaly detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_selected.drop('Label', axis=1)\n",
    "y = df_selected['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (500626, 10)\n",
      "Testing set size: (125157, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Testing set size: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Basic Decision Tree Accuracy: 0.9975\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      8015\n",
      "         1.0       1.00      1.00      1.00    117142\n",
      "\n",
      "    accuracy                           1.00    125157\n",
      "   macro avg       0.99      0.98      0.99    125157\n",
      "weighted avg       1.00      1.00      1.00    125157\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[  7770    245]\n",
      " [    67 117075]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = dt_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nBasic Decision Tree Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5}\n",
      "Best Cross-Validation Score: 0.9976\n",
      "\n",
      "Optimized Decision Tree Accuracy: 0.9976\n",
      "\n",
      "Optimized Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      8015\n",
      "         1.0       1.00      1.00      1.00    117142\n",
      "\n",
      "    accuracy                           1.00    125157\n",
      "   macro avg       1.00      0.98      0.99    125157\n",
      "weighted avg       1.00      1.00      1.00    125157\n",
      "\n",
      "\n",
      "Optimized Confusion Matrix:\n",
      "[[  7767    248]\n",
      " [    54 117088]]\n",
      "\n",
      "Feature Importances:\n",
      "Dst_Port: 0.7717\n",
      "Init_Bwd_Win_Byts: 0.0652\n",
      "Idle_Max: 0.0246\n",
      "Flow_Pkts/s: 0.0276\n",
      "Flow_IAT_Std: 0.0510\n",
      "Flow_IAT_Mean: 0.0364\n",
      "Fwd_Header_Len: 0.0033\n",
      "Idle_Mean: 0.0076\n",
      "Idle_Min: 0.0024\n",
      "Fwd_IAT_Tot: 0.0101\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Hyperparameter tuning with GridSearchCV\n",
    "param_grid = {\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=DecisionTreeClassifier(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    scoring='accuracy'\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score\n",
    "print(f\"\\nBest Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Cross-Validation Score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Step 8: Evaluate the optimized model\n",
    "best_dt = grid_search.best_estimator_\n",
    "y_pred_optimized = best_dt.predict(X_test)\n",
    "\n",
    "optimized_accuracy = accuracy_score(y_test, y_pred_optimized)\n",
    "print(f\"\\nOptimized Decision Tree Accuracy: {optimized_accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nOptimized Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_optimized))\n",
    "\n",
    "print(\"\\nOptimized Confusion Matrix:\")\n",
    "cm_optimized = confusion_matrix(y_test, y_pred_optimized)\n",
    "print(cm_optimized)\n",
    "\n",
    "# Step 9: Feature importance analysis\n",
    "feature_importance = best_dt.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(range(len(sorted_idx)), feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(range(len(sorted_idx)), np.array(X.columns)[sorted_idx])\n",
    "plt.title('Feature Importance in Decision Tree Model')\n",
    "plt.xlabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nFeature Importances:\")\n",
    "for i, col in enumerate(X.columns):\n",
    "    print(f\"{col}: {feature_importance[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tree is too large to visualize effectively. Consider reducing max_depth for visualization.\n",
      "\n",
      "5-Fold Cross-Validation Accuracy: 0.9976 ± 0.0001\n",
      "\n",
      "Learning curve saved as 'learning_curve.png'\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "# Visualize the decision tree (for smaller trees)\n",
    "if best_dt.tree_.node_count < 50:  # Only visualize if tree is not too big\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    tree.plot_tree(best_dt, filled=True, feature_names=X.columns, class_names=[str(c) for c in best_dt.classes_])\n",
    "    plt.title('Decision Tree Visualization')\n",
    "    plt.savefig('decision_tree.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(\"\\nDecision tree visualization saved as 'decision_tree.png'\")\n",
    "else:\n",
    "    print(\"\\nTree is too large to visualize effectively. Consider reducing max_depth for visualization.\")\n",
    "\n",
    "# Cross-validation for robust performance estimation\n",
    "cv_scores = cross_val_score(best_dt, X, y, cv=5, scoring='accuracy')\n",
    "print(f\"\\n5-Fold Cross-Validation Accuracy: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n",
    "\n",
    "# Learning curve analysis to detect overfitting/underfitting\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    best_dt, X, y, cv=5, n_jobs=-1, \n",
    "    train_sizes=np.linspace(0.1, 1.0, 10), scoring='accuracy')\n",
    "\n",
    "# Calculate mean and std for train and test scores\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_sizes, train_mean, label='Training score', color='blue', marker='o')\n",
    "plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.15, color='blue')\n",
    "plt.plot(train_sizes, test_mean, label='Cross-validation score', color='green', marker='s')\n",
    "plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.15, color='green')\n",
    "plt.title('Learning Curve')\n",
    "plt.xlabel('Training Examples')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.savefig('learning_curve.png')\n",
    "plt.close()\n",
    "print(\"\\nLearning curve saved as 'learning_curve.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best model saved as 'best_decision_tree_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Save the model for future use\n",
    "import joblib\n",
    "joblib.dump(best_dt, 'best_decision_tree_model.pkl')\n",
    "print(\"\\nBest model saved as 'best_decision_tree_model.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to make new predictions\n",
    "def predict_label(new_data):\n",
    "    \"\"\"\n",
    "    Make predictions using the trained model\n",
    "    \n",
    "    Parameters:\n",
    "    new_data (DataFrame): DataFrame with the same features as the training data\n",
    "    \n",
    "    Returns:\n",
    "    array: Predicted class labels\n",
    "    \"\"\"\n",
    "    # Ensure the data has the same features\n",
    "    required_columns = X.columns\n",
    "    if not all(col in new_data.columns for col in required_columns):\n",
    "        missing = [col for col in required_columns if col not in new_data.columns]\n",
    "        raise ValueError(f\"Missing columns in input data: {missing}\")\n",
    "    \n",
    "    # Select only the required columns in the correct order\n",
    "    new_data = new_data[required_columns]\n",
    "    \n",
    "    # Replace infinities and NaNs\n",
    "    new_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    for col in new_data.columns:\n",
    "        if new_data[col].isnull().any():\n",
    "            new_data[col].fillna(X[col].median(), inplace=True)\n",
    "    \n",
    "    # Make predictions\n",
    "    return best_dt.predict(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
